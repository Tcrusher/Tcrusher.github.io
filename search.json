[{"title":"汇编语言","url":"%2F2019%2F09%2F07%2F%E6%B1%87%E7%BC%96%E8%AF%AD%E8%A8%80.html","content":"\n汇编语言的学习，一点笔记。。。\n\n<!--more-->\n\n## 1、汇编语言介绍\n\n## 2、变量、寄存器与数据移动\n\n### 2.1、Hello World\n\n### 2.2、变量声明\n\n变量名必须以字母打头，其后可以跟着字母数字，可以包含‘_’，'@'，'$'特殊符号，但是通常避免使用特殊符号。**变量名不区分大小写，最大长度为247个字符，通常变量名有1~10个字符组成。**\n\n| 类型   | 占比特位数 | 表示范围（包含） |\n| ------ | ---------- | ---------------- |\n| sdword | 32         |                  |\n| dword  | 32         |                  |\n| sword  | 16         |                  |\n| word   | 16         |                  |\n| sbyte  | 8          | -128~127         |\n| byte   | 8          | 0~255            |\n\n```c\nint num=5; //c语言\nnum sdword 5 ; num被初始化为5，汇编语言;表示注释\n\nchar grade;\ngrade byte ? ;?表示汇编程序不对其进行初始化操作\n\ngrades byte 'a','b','c' ; 声明字节数组\n\nname byte 'abc' ; 声明整体字符串\n\nname byte 'abc',0 ; 字符串结尾通常带有二进制0，占用1个字节，用于表示字符串结束\n```\n\n### 2.3、立即数\n\nmov","tags":["汇编语言"],"categories":["汇编语言"]},{"title":"Redis基础","url":"%2F2019%2F07%2F22%2FRedis%E5%9F%BA%E7%A1%80.html","content":"\nRedis：Remote Dictionary Server(远程字典服务器)\n\n<!--more-->\n\n### 1、Redis基础\n\n#### 1.1、安装\n\nRedis：Remote Dictionary Server(远程字典服务器)\n\n#### 1.2、配置\n\n### 2、命令\n\n- 启动Redis\n\n```shell\n[root@VM_0_15_centos ~]# redis-server\n```\n\n- 连接Redis\n\n```shell\n[root@VM_0_15_centos ~]# redis-cli\n127.0.0.1:6379>\n127.0.0.1:6379> PING\nPONG\n\n```\n\n执行**PING**命令，检查redis服务是否启动。\n\n- 远程服务\n\n```shell\n[root@VM_0_15_centos ~]# redis-cli -h host -p port -a password\n```\n\nport为端口号，password为redis服务的密码。\n\nRedis命令参考：<http://redisdoc.com/>\n\n### 3、键（key）\n\nRdis keys命令\n\n基本命令：<https://www.runoob.com/redis/redis-keys.html>\n\n常用命令：\n\n| 序号 | 命令               | 描述                                    |\n| ---- | ------------------ | --------------------------------------- |\n| 1    | DUMP key           | 序列化给定 key ，并返回被序列化的值     |\n| 2    | keys *             | 查看所有的key                           |\n| 3    | DEL key            | 在key存在时删除key                      |\n| 4    | EXISTS key         | 检查key是否存在                         |\n| 5    | EXPIRE key seconds | 设置key的过去时间（秒）                 |\n| 6    | PTTL key           | 返回 key 的剩余的过期时间（毫秒）       |\n| 7    | MOVE key db        | 将当前数据库的 key 移动到给定的数据库db |\n| 8    | TYPE key           | 查看key对应value的数据类型              |\n\n\n\n### 4、字符串（String）\n\nRedis String命令\n\n基本命令：<https://www.runoob.com/redis/redis-strings.html>\n\n常用命令：\n\n| 序号 | 命令                                      | 描述                                            |\n| ---- | ----------------------------------------- | ----------------------------------------------- |\n| 1    | SET/GET key                               | 设置/获取key的值                                |\n| 2    | APPEND key value                          | 追加value到key的末尾                            |\n| 3    | STRLEN key                                | 返回字符串长度                                  |\n| 4    | INCR/DECR key                             | vlaue增/减1，一定为数字                         |\n| 5    | INCRBY/DECRBY key increment               | vlaue增/减increment，一定为数字                 |\n| 6    | GETSRANGE/SETRANGE key  start end (value) | 设置/获取范围中的value                          |\n| 7    | SETEX key seconds value                   | key 的过期时间设为 seconds（秒）                |\n| 8    | SETNX key value                           | 只有在 key 不存在时设置 key 的值                |\n| 9    | MSET key value [key value ...]            | 设置多个key-value                               |\n| 10   | MGET key [key ...]                        | 获取多个value                                   |\n| 11   | MSETNX key value [key value ...]          | 只有在 key 不存在时设置 多个key 的值            |\n| 12   | GETSET key value                          | key 的值设为 value ，返回 key 的旧值(old value) |\n\n说明：\n\n- SET key value如果key存在，则覆盖原来的key-value\n- MSETNX key value [key value ...]，只要有存在的key，则全部设置不成功\n\n### 5、列表（List）\n\nRedis List命令\n\n基本命令：<https://www.runoob.com/redis/redis-hashes.html>\n\n常用命令：\n\n| 序号 | 命令                                 | 描述                                                         |\n| ---- | ------------------------------------ | ------------------------------------------------------------ |\n| 1    | LPUSH/RPUSH                          | 在列表中加入值                                               |\n| 2    | LRANGE key start stop                | 获取列表中范围内的元素                                       |\n| 3    | LPOP/RPOP key                        | pop出列表中的第一/最后一个值                                 |\n| 4    | LINDEX key index                     | 索引获取列表中的元素                                         |\n| 5    | LLEN key                             | 获取列表长度                                                 |\n| 6    | LREM key count value                 | 移除列表元素conut value                                      |\n| 7    | LTRIM key start stop                 | 对一个列表进行修剪(trim)，就是说，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 |\n| 8    | RPOPLPUSH source destination         | 移除列表的最后一个元素，并将该元素添加到另一个列表并返回     |\n| 9    | LSET key index value                 | 通过索引设置列表元素的值                                     |\n| 10   | LINSERT key BEFORE/AFTER pivot value | 在列表的元素前或者后插入元素                                 |\n\n### 6、哈希（Hash）\n\nRedis Hash命令\n\n基本命令：https://www.runoob.com/redis/redis-hashes.html\n\n常用命令：\n\n| 序号 | 命令                             | 描述                                   |\n| ---- | -------------------------------- | -------------------------------------- |\n| 1    | HSET/HGET key field value        | 设置/获取哈希表key中的字段field为value |\n| 2    | HMSET/HMGET key                  | 设置/获取哈希表key中多个字段           |\n| 3    | HVALS key                        | 获取哈希表中所有值                     |\n| 4    | HDEL key field [field ...]       | 删除key中的字段                        |\n| 5    | HLEN key                         | 获取哈希表中字段的数量                 |\n| 6    | HEXISTS key field                | 查看哈希表 key 中，指定的字段是否存在  |\n| 7    | HKEYS/HVALS key                  | 获取所有的字段名/值                    |\n| 8    | HINCRBY key field increment      | 字段值增加整数increment                |\n| 9    | HINCRBYFLOAT key field increment | 字段值增加浮点increment                |\n| 10   | HSETNX key field value           | 只有字段field不存在时，设置字段的值    |\n\nk-v模式不变，v是一个键值对\n\n### 7、集合（Set）\n\nRedis Set命令\n\n基本命令：https://www.runoob.com/redis/redis-sets.html\n\n常用命令：\n\n| 序号 | 命令                            | 描述                                                |\n| ---- | ------------------------------- | --------------------------------------------------- |\n| 1    | SADD key member [member ...]    | 添加一个或多个成员                                  |\n| 2    | SMEMBERS key                    | 返回集合中的所有成员                                |\n| 3    | SISMEMBER key member            | 判断元素是否在集合中                                |\n| 4    | SCARD key                       | 返回集合中的元素个数                                |\n| 5    | SREM key member [member ...]    | 移除集合中一个或多个元素                            |\n| 6    | SRANDMEMBER key [count]         | 返回集合中一个或多个随机数                          |\n| 7    | SPOP key [count]                | 移除并返回集合中的一个或多个随机元素                |\n| 8    | SMOVE source destination member | 将 member 元素从 source 集合移动到 destination 集合 |\n| 9    | SDIFF key [key ...]             | 差集                                                |\n| 10   | SINTER key [key ...]            | 交集                                                |\n| 11   | SUNION key [key ...]            | 并集                                                |\n\n### 8、有序集合Zset（Sorted Set）\n\n在set的基础上，加上一个score值，zset：key score1 value1 score2 value2......\n\nRedis Sorted Set命令\n\n基本命令：https://www.runoob.com/redis/redis-sorted-sets.html\n\n常用命令：\n\n| 序号 | 命令                                                         | 描述                                                         |\n| ---- | ------------------------------------------------------------ | ------------------------------------------------------------ |\n| 1    | ZADD/ZRANGE                                                  | 增添/查询，withscores查询出score                             |\n| 2    | ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]  | 查询从min到max，‘（’不包含，                                 |\n| 3    | ZRANGE key start stop [WITHSCORES]                           | 移除有序集合中的一个或多个成员                               |\n| 4    | ZCARD/ZCOUNT key [min max]                                   | 获取有序集合的成员数                                         |\n| 5    | ZSCORE key member                                            | 返回有序集中，成员的分数值                                   |\n| 6    | ZREVRANK key member                                          | 返回有序集合中指定成员的排名，有序集成员按分数值递减(从大到小)排序 |\n| 7    | ZREVRANGE key start stop [WITHSCORES]                        | 逆序返回                                                     |\n| 8    | ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] | 返回有序集中指定分数区间内的成员，分数从高到低排序           |\n\n说明：  ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]，withscores：查询出带有score，‘（’：不包含，LIMIT offset count返回限制。\n\n```shell\n127.0.0.1:6379> ZRANGE zset 0 -1\n1) \"v1\"\n2) \"v2\"\n3) \"v3\"\n4) \"v4\"\n5) \"v5\"\n127.0.0.1:6379> ZRANGE zset 0 -1 WITHSCORES\n 1) \"v1\"\n 2) \"1\"\n 3) \"v2\"\n 4) \"2\"\n 5) \"v3\"\n 6) \"3\"\n 7) \"v4\"\n 8) \"4\"\n 9) \"v5\"\n10) \"5\"\n127.0.0.1:6379> ZRANGEBYSCORE zset (0 (5\n1) \"v1\"\n2) \"v2\"\n3) \"v3\"\n4) \"v4\"\n127.0.0.1:6379> ZRANGEBYSCORE zset 0 5 LIMIT 2 2\n1) \"v3\"\n2) \"v4\"\n```\n\n### 9、解析配置文件\n\n#### 9.1、Redis配置\n\nRedis的配置文件在Redis的安装目录下，文件名为redis.conf(windows上：redis.windows.conf)\n\n- 获取配置项\n\n```shell\nCONFIG GET 配置项名\n```\n\n- 获取所有配置项\n\n```shell\nCONFIG GET *\n```\n\n```shel\n127.0.0.1:6379> CONFIG GET *\n  1) \"dbfilename\"\n  2) \"dump.rdb\"\n  3) \"requirepass\"\n  4) \"\"\n  5) \"masterauth\"\n  6) \"\"\n  7) \"cluster-announce-ip\"\n  8) \"\"\n  9) \"unixsocket\"\n 10) \"\"\n 11) \"logfile\"\n 12) \"\"\n 13) \"pidfile\"\n 14) \"\"\n 15) \"slave-announce-ip\"\n 16) \"\"\n 17) \"replica-announce-ip\"\n 18) \"\"\n 19) \"maxmemory\"\n 20) \"0\"\n 21) \"proto-max-bulk-len\"\n 22) \"536870912\"\n 23) \"client-query-buffer-limit\"\n 24) \"1073741824\"\n 25) \"maxmemory-samples\"\n 26) \"5\"\n 27) \"lfu-log-factor\"\n 28) \"10\"\n 29) \"lfu-decay-time\"\n 30) \"1\"\n 31) \"timeout\"\n 32) \"0\"\n 33) \"active-defrag-threshold-lower\"\n 34) \"10\"\n 35) \"active-defrag-threshold-upper\"\n 36) \"100\"\n 37) \"active-defrag-ignore-bytes\"\n 38) \"104857600\"\n 39) \"active-defrag-cycle-min\"\n 40) \"5\"\n 41) \"active-defrag-cycle-max\"\n 42) \"75\"\n 43) \"active-defrag-max-scan-fields\"\n 44) \"1000\"\n 45) \"auto-aof-rewrite-percentage\"\n 46) \"100\"\n 47) \"auto-aof-rewrite-min-size\"\n 48) \"67108864\"\n 49) \"hash-max-ziplist-entries\"\n 50) \"512\"\n 51) \"hash-max-ziplist-value\"\n 52) \"64\"\n 53) \"stream-node-max-bytes\"\n 54) \"4096\"\n 55) \"stream-node-max-entries\"\n 56) \"100\"\n 57) \"list-max-ziplist-size\"\n 58) \"-2\"\n 59) \"list-compress-depth\"\n 60) \"0\"\n 61) \"set-max-intset-entries\"\n 62) \"512\"\n 63) \"zset-max-ziplist-entries\"\n 64) \"128\"\n 65) \"zset-max-ziplist-value\"\n 66) \"64\"\n 67) \"hll-sparse-max-bytes\"\n 68) \"3000\"\n 69) \"lua-time-limit\"\n 70) \"5000\"\n 71) \"slowlog-log-slower-than\"\n 72) \"10000\"\n 73) \"latency-monitor-threshold\"\n 74) \"0\"\n 75) \"slowlog-max-len\"\n 76) \"128\"\n 77) \"port\"\n 78) \"6379\"\n 79) \"cluster-announce-port\"\n 80) \"0\"\n 81) \"cluster-announce-bus-port\"\n 82) \"0\"\n 83) \"tcp-backlog\"\n 84) \"511\"\n 85) \"databases\"\n 86) \"16\"\n 87) \"repl-ping-slave-period\"\n 88) \"10\"\n 89) \"repl-ping-replica-period\"\n 90) \"10\"\n 91) \"repl-timeout\"\n 92) \"60\"\n 93) \"repl-backlog-size\"\n 94) \"1048576\"\n 95) \"repl-backlog-ttl\"\n 96) \"3600\"\n 97) \"maxclients\"\n 98) \"10000\"\n 99) \"watchdog-period\"\n100) \"0\"\n101) \"slave-priority\"\n102) \"100\"\n103) \"replica-priority\"\n104) \"100\"\n105) \"slave-announce-port\"\n106) \"0\"\n107) \"replica-announce-port\"\n108) \"0\"\n109) \"min-slaves-to-write\"\n110) \"0\"\n111) \"min-replicas-to-write\"\n112) \"0\"\n113) \"min-slaves-max-lag\"\n114) \"10\"\n115) \"min-replicas-max-lag\"\n116) \"10\"\n117) \"hz\"\n118) \"10\"\n119) \"cluster-node-timeout\"\n120) \"15000\"\n121) \"cluster-migration-barrier\"\n122) \"1\"\n123) \"cluster-slave-validity-factor\"\n124) \"10\"\n125) \"cluster-replica-validity-factor\"\n126) \"10\"\n127) \"repl-diskless-sync-delay\"\n128) \"5\"\n129) \"tcp-keepalive\"\n130) \"300\"\n131) \"cluster-require-full-coverage\"\n132) \"yes\"\n133) \"cluster-slave-no-failover\"\n134) \"no\"\n135) \"cluster-replica-no-failover\"\n136) \"no\"\n137) \"no-appendfsync-on-rewrite\"\n138) \"no\"\n139) \"slave-serve-stale-data\"\n140) \"yes\"\n141) \"replica-serve-stale-data\"\n142) \"yes\"\n143) \"slave-read-only\"\n144) \"yes\"\n145) \"replica-read-only\"\n146) \"yes\"\n147) \"slave-ignore-maxmemory\"\n148) \"yes\"\n149) \"replica-ignore-maxmemory\"\n150) \"yes\"\n151) \"stop-writes-on-bgsave-error\"\n152) \"yes\"\n153) \"daemonize\"\n154) \"no\"\n155) \"rdbcompression\"\n156) \"yes\"\n157) \"rdbchecksum\"\n158) \"yes\"\n159) \"activerehashing\"\n160) \"yes\"\n161) \"activedefrag\"\n162) \"no\"\n163) \"protected-mode\"\n164) \"yes\"\n165) \"repl-disable-tcp-nodelay\"\n166) \"no\"\n167) \"repl-diskless-sync\"\n168) \"no\"\n169) \"aof-rewrite-incremental-fsync\"\n170) \"yes\"\n171) \"rdb-save-incremental-fsync\"\n172) \"yes\"\n173) \"aof-load-truncated\"\n174) \"yes\"\n175) \"aof-use-rdb-preamble\"\n176) \"yes\"\n177) \"lazyfree-lazy-eviction\"\n178) \"no\"\n179) \"lazyfree-lazy-expire\"\n180) \"no\"\n181) \"lazyfree-lazy-server-del\"\n182) \"no\"\n183) \"slave-lazy-flush\"\n184) \"no\"\n185) \"replica-lazy-flush\"\n186) \"no\"\n187) \"dynamic-hz\"\n188) \"yes\"\n189) \"maxmemory-policy\"\n190) \"noeviction\"\n191) \"loglevel\"\n192) \"notice\"\n193) \"supervised\"\n194) \"no\"\n195) \"appendfsync\"\n196) \"everysec\"\n197) \"syslog-facility\"\n198) \"local0\"\n199) \"appendonly\"\n200) \"no\"\n201) \"dir\"\n202) \"/usr/local/redis/bin\"\n203) \"save\"\n204) \"3600 1 300 100 60 10000\"\n205) \"client-output-buffer-limit\"\n206) \"normal 0 0 0 slave 268435456 67108864 60 pubsub 33554432 8388608 60\"\n207) \"unixsocketperm\"\n208) \"0\"\n209) \"slaveof\"\n210) \"\"\n211) \"notify-keyspace-events\"\n212) \"\"\n213) \"bind\"\n214) \"\"\n```\n\n- 修改配置项\n\n```shell\nCONFIG SET 配置项名 属性\n```\n\n当然有些配置需要在配置文件中修改才会生效，保存\n\n#### 9.2、配置文件详解\n\n文件来自：https://www.cnblogs.com/zhang-ke/p/5981108.html\n\n```shell\n#redis.conf\n# Redis configuration file example.\n# ./redis-server /path/to/redis.conf\n\n################################## INCLUDES ###################################\n#这在你有标准配置模板但是每个redis服务器又需要个性设置的时候很有用。\n# include /path/to/local.conf\n# include /path/to/other.conf\n\n################################ GENERAL #####################################\n\n#是否在后台执行，yes：后台运行；no：不是后台运行（老版本默认）\ndaemonize yes\n\n  #3.2里的参数，是否开启保护模式，默认开启。要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问。要是开启了密码   和bind，可以开启。否   则最好关闭，设置为no。\n  protected-mode yes\n#redis的进程文件\npidfile /var/run/redis/redis-server.pid\n\n#redis监听的端口号。\nport 6379\n\n#此参数确定了TCP连接中已完成队列(完成三次握手之后)的长度， 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。\ntcp-backlog 511\n\n#指定 redis 只接收来自于该 IP 地址的请求，如果不进行设置，那么将处理所有请求\nbind 127.0.0.1\n\n#配置unix socket来让redis支持监听本地连接。\n# unixsocket /var/run/redis/redis.sock\n#配置unix socket使用文件的权限\n# unixsocketperm 700\n\n# 此参数为设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。\ntimeout 0\n\n#tcp keepalive参数。如果设置不为0，就使用配置tcp的SO_KEEPALIVE值，使用keepalive有两个好处:检测挂掉的对端。降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。\ntcp-keepalive 0\n\n#指定了服务端日志的级别。级别包括：debug（很多信息，方便开发、测试），verbose（许多有用的信息，但是没有debug级别信息多），notice（适当的日志级别，适合生产环境），warn（只有非常重要的信息）\nloglevel notice\n\n#指定了记录日志的文件。空字符串的话，日志会打印到标准输出设备。后台运行的redis标准输出是/dev/null。\nlogfile /var/log/redis/redis-server.log\n\n#是否打开记录syslog功能\n# syslog-enabled no\n\n#syslog的标识符。\n# syslog-ident redis\n\n#日志的来源、设备\n# syslog-facility local0\n\n#数据库的数量，默认使用的数据库是DB 0。可以通过”SELECT “命令选择一个db\ndatabases 16\n\n################################ SNAPSHOTTING ################################\n# 快照配置\n# 注释掉“save”这一行配置项就可以让保存数据库功能失效\n# 设置sedis进行数据库镜像的频率。\n# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） \n# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） \n# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）\nsave 900 1\nsave 300 10\nsave 60 10000\n\n#当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误\nstop-writes-on-bgsave-error yes\n\n#使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间\nrdbcompression yes\n\n#是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。\nrdbchecksum yes\n\n#rdb文件的名称\ndbfilename dump.rdb\n\n#数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录\ndir /var/lib/redis\n\n################################# REPLICATION #################################\n#复制选项，slave复制对应的master。\n# slaveof <masterip> <masterport>\n\n#如果master设置了requirepass，那么slave要连上master，需要有master的密码才行。masterauth就是用来配置master的密码，这样可以在连上master后进行认证。\n# masterauth <master-password>\n\n#当从库同主机失去连接或者复制正在进行，从机库有两种运行方式：1) 如果slave-serve-stale-data设置为yes(默认设置)，从库会继续响应客户端的请求。2) 如果slave-serve-stale-data设置为no，除去INFO和SLAVOF命令之外的任何请求都会返回一个错误”SYNC with master in progress”。\nslave-serve-stale-data yes\n\n#作为从服务器，默认情况下是只读的（yes），可以修改成NO，用于写（不建议）。\nslave-read-only yes\n\n#是否使用socket方式复制数据。目前redis复制提供两种方式，disk和socket。如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。有2种方式：disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。socket的方式就的一个个slave顺序复制。在磁盘速度缓慢，网速快的情况下推荐用socket方式。\nrepl-diskless-sync no\n\n#diskless复制的延迟时间，防止设置为0。一旦复制开始，节点不会再接收新slave的复制请求直到下一个rdb传输。所以最好等待一段时间，等更多的slave连上来。\nrepl-diskless-sync-delay 5\n\n#slave根据指定的时间间隔向服务器发送ping请求。时间间隔可以通过 repl_ping_slave_period 来设置，默认10秒。\n# repl-ping-slave-period 10\n\n#复制连接超时时间。master和slave都有超时时间的设置。master检测到slave上次发送的时间超过repl-timeout，即认为slave离线，清除该slave信息。slave检测到上次和master交互的时间超过repl-timeout，则认为master离线。需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时。\n# repl-timeout 60\n\n#是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。\nrepl-disable-tcp-nodelay no\n\n#复制缓冲区大小，这是一个环形复制缓冲区，用来保存最新复制的命令。这样在slave离线的时候，不需要完全复制master的数据，如果可以执行部分同步，只需要把缓冲区的部分数据复制给slave，就能恢复正常复制状态。缓冲区的大小越大，slave离线的时间可以更长，复制缓冲区只有在有slave连接的时候才分配内存。没有slave的一段时间，内存会被释放出来，默认1m。\n# repl-backlog-size 5mb\n\n#master没有slave一段时间会释放复制缓冲区的内存，repl-backlog-ttl用来设置该时间长度。单位为秒。\n# repl-backlog-ttl 3600\n\n#当master不可用，Sentinel会根据slave的优先级选举一个master。最低的优先级的slave，当选master。而配置成0，永远不会被选举。\nslave-priority 100\n\n#redis提供了可以让master停止写入的方式，如果配置了min-slaves-to-write，健康的slave的个数小于N，mater就禁止写入。master最少得有多少个健康的slave存活才能执行写命令。这个配置虽然不能保证N个slave都一定能接收到master的写操作，但是能避免没有足够健康的slave的时候，master不能写入来避免数据丢失。设置为0是关闭该功能。\n# min-slaves-to-write 3\n\n#延迟小于min-slaves-max-lag秒的slave才认为是健康的slave。\n# min-slaves-max-lag 10\n\n# 设置1或另一个设置为0禁用这个特性。\n# Setting one or the other to 0 disables the feature.\n# By default min-slaves-to-write is set to 0 (feature disabled) and\n# min-slaves-max-lag is set to 10.\n\n################################## SECURITY ###################################\n#requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。\n# requirepass foobared\n\n#把危险的命令给修改成其他名称。比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。\n# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52\n\n#设置成一个空的值，可以禁止一个命令\n# rename-command CONFIG \"\"\n################################### LIMITS ####################################\n\n# 设置能连上redis的最大客户端连接数量。默认是10000个客户端连接。由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。如果超过了maxclients，redis会给新的连接发送’max number of clients reached’，并关闭连接。\n# maxclients 10000\n\n#redis配置的最大内存容量。当内存满了，需要配合maxmemory-policy策略进行处理。注意slave的输出缓冲区是不计算在maxmemory内的。所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。\n# maxmemory <bytes>\n\n#内存容量超过maxmemory后的处理策略。\n#volatile-lru：利用LRU算法移除设置过过期时间的key。\n#volatile-random：随机移除设置过过期时间的key。\n#volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）\n#allkeys-lru：利用LRU算法移除任何key。\n#allkeys-random：随机移除任何key。\n#noeviction：不移除任何key，只是返回一个写错误。\n#上面的这些驱逐策略，如果redis没有合适的key驱逐，对于写命令，还是会返回错误。redis将不再接收写请求，只接收get请求。写命令包括：set setnx setex append incr decr rpush lpush rpushx lpushx linsert lset rpoplpush sadd sinter sinterstore sunion sunionstore sdiff sdiffstore zadd zincrby zunionstore zinterstore hset hsetnx hmset hincrby incrby decrby getset mset msetnx exec sort。\n# maxmemory-policy noeviction\n\n#lru检测的样本数。使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。\n# maxmemory-samples 5\n\n############################## APPEND ONLY MODE ###############################\n#默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。\nappendonly no\n\n#aof文件名\nappendfilename \"appendonly.aof\"\n\n#aof持久化策略的配置\n#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。\n#always表示每次写入都执行fsync，以保证数据同步到磁盘。\n#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。\nappendfsync everysec\n\n# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。\nno-appendfsync-on-rewrite no\n\n#aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。\nauto-aof-rewrite-percentage 100\n#设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写\nauto-aof-rewrite-min-size 64mb\n\n#aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。\naof-load-truncated yes\n\n################################ LUA SCRIPTING ###############################\n# 如果达到最大时间限制（毫秒），redis会记个log，然后返回error。当一个脚本超过了最大时限。只有SCRIPT KILL和SHUTDOWN NOSAVE可以用。第一个可以杀没有调write命令的东西。要是已经调用了write，只能用第二个命令杀。\nlua-time-limit 5000\n\n################################ REDIS CLUSTER ###############################\n#集群开关，默认是不开启集群模式。\n# cluster-enabled yes\n\n#集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突\n# cluster-config-file nodes-6379.conf\n\n#节点互连超时的阀值。集群节点超时毫秒数\n# cluster-node-timeout 15000\n\n#在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：\n#比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period\n#如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移 \n# cluster-slave-validity-factor 10\n\n#master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。\n# cluster-migration-barrier 1\n\n#默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。\n# cluster-require-full-coverage yes\n\n################################## SLOW LOG ###################################\n###slog log是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。\n#执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。\nslowlog-log-slower-than 10000\n\n#慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉。这个长度没有限制。只要有足够的内存就行。你可以通过 SLOWLOG RESET 来释放内存。\nslowlog-max-len 128\n\n################################ LATENCY MONITOR ##############################\n#延迟监控功能是用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。0的话，就是关闭监视。默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。\nlatency-monitor-threshold 0\n\n############################# EVENT NOTIFICATION ##############################\n#键空间通知使得客户端可以通过订阅频道或模式，来接收那些以某种方式改动了 Redis 数据集的事件。因为开启键空间通知功能需要消耗一些 CPU ，所以在默认配置下，该功能处于关闭状态。\n#notify-keyspace-events 的参数可以是以下字符的任意组合，它指定了服务器该发送哪些类型的通知：\n##K 键空间通知，所有通知以 __keyspace@__ 为前缀\n##E 键事件通知，所有通知以 __keyevent@__ 为前缀\n##g DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知\n##$ 字符串命令的通知\n##l 列表命令的通知\n##s 集合命令的通知\n##h 哈希命令的通知\n##z 有序集合命令的通知\n##x 过期事件：每当有过期键被删除时发送\n##e 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送\n##A 参数 g$lshzxe 的别名\n#输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何 通知被分发。详细使用可以参考http://redis.io/topics/notifications\n\nnotify-keyspace-events \"\"\n\n############################### ADVANCED CONFIG ###############################\n#数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hash\nhash-max-ziplist-entries 512\n#value大小小于等于hash-max-ziplist-value的用ziplist，大于hash-max-ziplist-value用hash。\nhash-max-ziplist-value 64\n\n#数据量小于等于list-max-ziplist-entries用ziplist，大于list-max-ziplist-entries用list。\nlist-max-ziplist-entries 512\n#value大小小于等于list-max-ziplist-value的用ziplist，大于list-max-ziplist-value用list。\nlist-max-ziplist-value 64\n\n#数据量小于等于set-max-intset-entries用iniset，大于set-max-intset-entries用set。\nset-max-intset-entries 512\n\n#数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zset。\nzset-max-ziplist-entries 128\n#value大小小于等于zset-max-ziplist-value用ziplist，大于zset-max-ziplist-value用zset。\nzset-max-ziplist-value 64\n\n#value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse），大于hll-sparse-max-bytes使用稠密的数据结构（dense）。一个比16000大的value是几乎没用的，建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右。\nhll-sparse-max-bytes 3000\n\n#Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存。\nactiverehashing yes\n\n##对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。\n#对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的。\nclient-output-buffer-limit normal 0 0 0\n#对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。\nclient-output-buffer-limit slave 256mb 64mb 60\n#对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。\nclient-output-buffer-limit pubsub 32mb 8mb 60\n\n#redis执行任务的频率为1s除以hz。\nhz 10\n\n#在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值。\naof-rewrite-incremental-fsync yes\n```\n\ntcp-keepalive：如果设置为0，则不会进行keepalive检查，建议设置为60，单位为秒。\n\nloglevel：指定日志记录级别，Redis 总共支持四个级别：debug、verbose、notice、warning，默认为 notice\n\n### 10、Redis的持久化\n\n- RDB(Redis DataBase)\n\n在指定的时间间隔内将内存中的数据集快照写入磁盘，（Snapshot快照），它恢复时将快照文件直接读入到内存里。\n\nRedis会单独创建（fork）一个子进程来进行持久化，会先将数据写入到一个临时文件中，待持久化进程都结束了，再用这个临时文件替代上次持久化的文件。整个过程中，主进程是不进行任何IO操作的，这就保证了极高的性能。如需要进行大规模数据的恢复，且对于数据恢复的完整性不是非常敏感，南无RDB方式要比AOF方式更加高效，RDB的缺点是最后一次持久化后的数据可能丢失。\n\nFork的作用时复制一个与当前一样的进程。新进程的所有数据（变量，环境变量，程序计数器等）数值都和原来进程一致，但是是一个全新的进程，并作为原进程的子进程。\n\nRDB保存的是dump.rdb文件\n\nSNAPSHOTTING快照：\n\n```shell\n################################ SNAPSHOTTING ################################\n# 快照配置\n# 注释掉“save”这一行配置项就可以让保存数据库功能失效\n# 设置sedis进行数据库镜像的频率。\n# 900秒（15分钟）内至少1个key值改变（则进行数据库保存--持久化） \n# 300秒（5分钟）内至少10个key值改变（则进行数据库保存--持久化） \n# 60秒（1分钟）内至少10000个key值改变（则进行数据库保存--持久化）\nsave 900 1\nsave 300 10\nsave 60 10000\n\n#当RDB持久化出现错误后，是否依然进行继续进行工作，yes：不能进行工作，no：可以继续进行工作，可以通过info中的rdb_last_bgsave_status了解RDB持久化是否有错误\nstop-writes-on-bgsave-error yes\n\n#使用压缩rdb文件，rdb文件压缩使用LZF压缩算法，yes：压缩，但是需要一些cpu的消耗。no：不压缩，需要更多的磁盘空间\nrdbcompression yes\n\n#是否校验rdb文件。从rdb格式的第五个版本开始，在rdb文件的末尾会带上CRC64的校验和。这跟有利于文件的容错性，但是在保存rdb文件的时候，会有大概10%的性能损耗，所以如果你追求高性能，可以关闭该配置。\nrdbchecksum yes\n\n#rdb文件的名称\ndbfilename dump.rdb\n\n#数据目录，数据库的写入会在这个目录。rdb、aof文件也会写在这个目录\ndir /var/lib/redis\n```\n\nSHUTDOWN：关闭连接，redis迅速生成dump.rdb，一般需要备份好dump.rdb文件。cp dump.rdb dump_new.rdb(一般在不同机器)\n\nsave/bgsave：迅速备份，save只管保存，其他不管，全部阻塞。bgsave在后台异步进行快照操作，快照同时还可以响应客服请求，可以通过lastsave命令获取最后一次成功执行快照的时间。\n\nflushall：也会产生dump.rdb，但是为空，所以说。。。\n\n\n\n- AOF(Append Only File)\n\n以日志文件来记录每一个操作，将Redis执行过得所有写的指令记下来（读操作不记录），只许追加文件但不可以改写文件，redis启动之初会读取该文件重新构建数据，也就是：redis重启的话就根据日志文件内容将写指令从前到后执行一次以完成数据的恢复工作。\n\n```shell\n############################## APPEND ONLY MODE ###############################\n#默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。但是redis如果中途宕机，会导致可能有几分钟的数据丢失，根据save来策略进行持久化，Append Only File是另一种持久化方式，可以提供更好的持久化特性。Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。no不表示不使用，改为yes打开aof持久化\nappendonly no\n\n#aof文件名\nappendfilename \"appendonly.aof\"\n\n#aof持久化策略的配置\n#no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。\n#always表示每次写入都执行fsync，以保证数据同步到磁盘。\n#everysec表示每秒执行一次fsync，可能会导致丢失这1s数据。\nappendfsync everysec\n\n# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间，no-appendfsync-on-rewrite字段设置为默认设置为no。如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。\nno-appendfsync-on-rewrite no\n\n#aof自动重写配置。当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。\nauto-aof-rewrite-percentage 100\n#设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写\nauto-aof-rewrite-min-size 64mb\n\n#aof文件可能在尾部是不完整的，当redis启动的时候，aof文件的数据被载入内存。重启可能发生在redis所在的主机操作系统宕机后，尤其在ext4文件系统没有加上data=ordered选项（redis宕机或者异常终止不会造成尾部不完整现象。）出现这种现象，可以选择让redis退出，或者导入尽可能多的数据。如果选择的是yes，当截断的aof文件被导入的时候，会自动发布一个log给客户端然后load。如果是no，用户必须手动redis-check-aof修复AOF文件才可以。\naof-load-truncated yes\n```\n\nappendonly.aof与dump.rdb可以同时存在，优先选择appendonly.aof\n\n修复：当写入突然断网，大量数据，appendonly.aof出现错误，redis无法启动，可以使用redis-check-aof检查appendonly.aof，会去掉不符合语法部分。再次重新启动。\n\nRewrite：AOF采用文件追加方式，文件会越来越大，于是新增了重写机制，当AOF文件的大小超过所设置的阈值时，Redis就会自动启动AOF文件的内容压缩，只保留可以恢复数据的最小指令，可以使用bgrewriteaof。\n\n重写原理：AOF文件持续增长而过大时，会fork出一条新进程来将文件重写（也是先写临时文件最后在rename），遍历新进程的内存中的数据，每条记录有一条set语句，重写aof文件操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容命令的方式重写了一个新的aof文件，与快照类似。\n\n触发机制：Redis会记录上次重写时的aof大小，默认配置是当aof文件大小是上次rewrite后大小的一倍且文件大于64M时触发。\n\n### 11、Redis的事务\n\n#### 11.1、事务介绍\n\nRedis中的事务(transaction)是一组命令的集合。事务同命令一样都是Redis最小的执行单位，一个事务中的命令要么都执行，要么都不执行。\n\n一个队列中，一次性执行，按照顺序，有顺序，排他性的执行一系列命令。\n\n| 序号 | 命令                | 描述                                                         |\n| ---- | ------------------- | ------------------------------------------------------------ |\n| 1    | MULTI               | 标记事务开始                                                 |\n| 2    | EXEC                | 执行所有事务块内的命令                                       |\n| 3    | DISCARD             | 取消事务，放弃执行事务块内的所有命令                         |\n| 4    | UNWATCH             | 取消 WATCH 命令对所有 key 的监视                             |\n| 5    | WATCH key [key ...] | 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断 |\n\n#### 11.2、Redis事务错误处理\n\n- 语法错误\n\n```shell\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set k3 v3\nQUEUED\n127.0.0.1:6379> set k4 v4\nQUEUED\n127.0.0.1:6379> sett k5 v5\n(error) ERR unknown command `sett`, with args beginning with: `k5`, `v5`, \n127.0.0.1:6379> EXEC\n(error) EXECABORT Transaction discarded because of previous errors.\n127.0.0.1:6379> keys *\n1) \"k2\"\n2) \"k1\"\n127.0.0.1:6379> get k3\n(nil)\n127.0.0.1:6379> \n```\n\n错误的命令导致事务中的其他命令都不执行了，可见事务中的所有命令式同呼吸共命运的。如果客户端在发送EXEC命令之前断线了，则服务器会清空事务队列，事务中的所有命令都不会被执行。而一旦客户端发送了EXEC命令之后，事务中的所有命令都会被执行，即使此后客户端断线也没关系，因为服务器已经保存了事务中的所有命令。\n\n- 运行错误\n\n```shell\n127.0.0.1:6379> MULTI\nOK\n127.0.0.1:6379> set k3 v3\nQUEUED\n127.0.0.1:6379> INCR k1\nQUEUED\n127.0.0.1:6379> set k4 v4\nQUEUED\n127.0.0.1:6379> EXEC\n1) OK\n2) (error) ERR value is not an integer or out of range\n3) OK\n127.0.0.1:6379> keys *\n1) \"k4\"\n2) \"k2\"\n3) \"k3\"\n4) \"k1\"\n127.0.0.1:6379> get k3\n\"v3\"\n127.0.0.1:6379> get k4\n\"v4\"\n127.0.0.1:6379> \n```\n\n运行错误在命令执行之前Redis是无法发现的，所以在事务里这样的命令会被Redis接受并执行。如果事务里有一条命令执行错误，其他命令依旧会执行（包括出错之后的命令）。\n\n悲观锁\n\n乐观锁\n\n一旦执行了EXEC，之前加的监控锁都会被取消。\n\n### 12、Redis的发布与订阅\n\n进程间的一种消息通信模式：发送者（pub）发送消息，订阅者（sub）接收消息。消息中间件一般不使用redis，了解了解。\n\n常用命令：\n\n| 序号 | 命令                                       | 描述                             |\n| ---- | ------------------------------------------ | -------------------------------- |\n| 1    | SUBSCRIBE channel [channel ...]            | 订阅给定的一个或多个频道的信息   |\n| 2    | PSUBSCRIBE pattern [pattern ...]           | 订阅一个或多个符合给定模式的频道 |\n| 3    | PUBSUB subcommand [argument [argument ...] | 查看订阅与发布系统状态           |\n| 4    | PUBLISH channel message                    | 将信息发送到指定的频道           |\n| 5    | PUNSUBSCRIBE [pattern [pattern ...]        | 退订所有给定模式的频道           |\n| 6    | UNSUBSCRIBE [channel [channel ...]         | 指退订给定的频道                 |\n\n```shell\nPSUBSCRIBE new*  #可以使用通配符，类似正则表达式\n```\n\n### 13、Redis的复制\n\n主从复制，主机数据更新后根据配置和策略，自动同步到备机的master/slaver机制，master以写为主，slaver以读为主。\n\n#### 13.1、配置\n\n- 配从（库）不配主（库）\n\n### 14、客户端\n\n","tags":["Redis"],"categories":["Redis"]},{"title":"My first blog","url":"%2F2019%2F05%2F06%2F%E6%88%91%E7%9A%84%E7%AC%AC%E4%B8%80%E7%AF%87%E5%8D%9A%E5%AE%A2.html","content":"\nMy first blog.\n\n<!--more-->\n\n## 第一章\n\n### 1.1、部署环境\n1、下载git、node.js，安装git、node.js\n2、安装hexo，初始化、启动、浏览器访问测试\n### 1.2、基本命令\n1、npm install、hexo init、hexo server\n\n---\n\n## 第二章\n### 2.1、创建博客\n1、\n2、\n\n---\n\n## 第三章\n内容\n","tags":["Programming Assignment"],"categories":["hello world"]},{"title":"Hello World","url":"%2F2019%2F05%2F06%2Fhello-world.html","content":"\nWelcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n<!--more-->\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/deployment.html)\n","tags":["Algorithms"],"categories":["hello world"]}]